---
layout: post
title:  "The dangers of the Single Global Process"
date:   2019-08-12 07:53:00
categories: elixir distribution
---

There are a few things I consider required reading. [To spawn, or not to spawn?](https://www.theerlangelist.com/article/spawn_or_not) by Sasa Juric
is definitely one of them. If you haven't read it you need to. It'll change the way you think about building elixir applications.

Seriously go read it.

When that post originally came out it changed the way that people thought about elixir apps, largely for the better. Modeling the domain with pure functions is a powerful approach and one that we should strive for when we can.

But, there was one pattern that emerged that I think has had some negative impacts on the community. That pattern is what I've been calling - for lack of a better name - the "single global process" pattern. Let's call it the SGP pattern for short. You've probably seen this pattern. Its the one where you do this elegant, functional domain modeling and then put it in a process somewhere. In Sasa's post the single process is the RoundServer.

I don't think Sasa's intention was to promote this pattern. I wasn't there when he was writing it but I always thought that using a single RoundServer to manage a round was somewhat incidental. The single process was an implementation detail and the important point was to model your domain with functions.

Because here's the thing. The SGP pattern introduces a *ton* of problems. Problems that you, dear reader, are going to need to solve. In my experience the SGP is one of the most complex patterns you can introduce to your system despite being one of the easiest to build. For the rest of this post I'm going to do my best to convince you of this by enumerating several of the problems that you'll face as well as some potential solutions.

## The Setup

In order to drive these points home we need a motivating example. I want to focus on the runtime concerns so I'm going to reduce our domain concerns to a simple counter. Here's our functional core:

```elixir
defmodule Counter do
  def new(initial \\ 0) do
    %{ops: [], initial: initial}
  end

  def incr(%{ops: ops}=counter) do
    %{counter | ops: [{:incr, 1} | ops]} 
  end

  def decr(%{ops: ops}=counter) do
    %{counter | ops: [{:decr, 1} | ops]}
  end

  def count(%{ops: ops, initial: init}) do
    Enum.reduce ops, init, fn op, count ->
      case op do
        {:incr, val} ->
          count + val

        {:decr, val} ->
          count - val
      end
    end
  end
end
```

In order to keep track of counts we add increment and decrement operations to a growing list. When we want to count them up we fold over the list either adding or decrementing starting from some initial value.

For the server we'll use a `GenServer`.

```elixir
defmodule CounterServer do
  use GenServer

  def start_link(opts) do
    GenServer.start_link(__MODULE__, opts, name: Keyword.get(opts, :name))
  end

  def increment(name) do
    GenServer.call(name, :incr)
  end

  def decrement(name) do
    GenServer.call(name, :decr)
  end

  def count(name) do
    GenServer.call(name, :get_count)
  end

  def init(_opts) do
    {:ok, Counter.new()}
  end

  def handle_call(:incr, _from, counter) do
    {:reply, :ok, Counter.incr(counter)}
  end

  def handle_call(:decr, _from, counter) do
    {:reply, :ok, Counter.decr(counter)}
  end

  def handle_call(:get_count, _from, counter) do
    {:reply, Counter.count(counter), counter}
  end
end
```

The server is equally trivial. It manages the lifecycle of a counter in response to calls. Unique counter servers are trivially started like so:

```elixir
CounterServer.start_link(name: "some-fancy-counter")
```

With that we have a good starting point to discuss problems with this design.

## The problem

What we have so far seems pretty good. And if all you really needed was a simple, in-memory counter this would probably do the trick. But this is a contrived domain that I've intentionally kept simple so I can focus on other things. Typically the state we deal with is *important*. The state that makes up most companies core domain is *not ephemeral*. The state that we're dealing with informs decisions that you're company will make in the future. That means it needs to be persisted. So lets add persistence. If persisting a counter to a database bothers you then you can tell yourself that the counter is used to bill clients for the use of your api.

The typical recommendation for persistence is to initialize the process with state from the database and persist any new writes. Using this pattern reads can come directly out of memory saving yourself the database roundtrip. Lets update our Counter Server to reflect this change:

```elixir
defmodule CounterServer do
  use GenServer

  def start_link(opts) do
    GenServer.start_link(__MODULE__, opts, name: Keyword.get(opts, :name))
  end

  def increment(name) do
    GenServer.call(name, :incr)
  end

  def decrement(name) do
    GenServer.call(name, :decr)
  end

  def count(name) do
    GenServer.call(name, :get_count)
  end

  def init(_opts) do
    data = %{
      counter: nil,
      name: opts[:name],
    }

    {:ok, data, {:continue, :load_state}}
  end

  def handle_continue(:loadstate, data) do
    {:ok, initial} = get_from_db(data.name)
    {:noreply, %{data | counter: Counter.new(initial)}}
  end

  def handle_call(:incr, _from, data) do
    new_counter = Counter.incr(data.counter)
    :ok = put_in_db(data.name, new_counter)

    {:reply, :ok, %{data | counter: new_counter}}
  end

  def handle_call(:decr, _from, data) do
    new_counter = Counter.decr(data.counter)
    :ok = put_in_db(data.name, new_counter)

    {:reply, :ok, %{data | counter: new_counter}}
  end

  def handle_call(:get_count, _from, data) do
    {:reply, Counter.count(data.counter), data}
  end
end
```

When the counter process starts we load the state in a `handle_continue` callback. If we receive an increment or decrement message we update the counter and put it into the database. Reads are returned from our in memory representation of the counter saving us that database call.

This seems great! Very elegant. And it _does_ work great - right up until you need to run on more then 1 node. Most companies need to run more then 1 node at some point whether for resiliency or to handle scale.

But here's our first problem. The counter we've created is node local. Its only a matter of time before we end up with duplicate counters on both of our nodes.

![load balanced nodes]({{ site.url }}/assets/images/sgp/unconnected_nodes.jpg)

If this situation occurs then we have a high likelyhood of returning incorrect counts from memory because we can't know if another node has written updated the counter in the database. We also have a high likelyhood of overwriting previously stored values. We're going to provide incorrect results and we have a high liklihood of losing data.

A quick aside about data integrity. Inconsistent data issues are some of the most nefarious bugs you'll encounter when working with distributed systems. Bugs like these suck so much because there's never a good indication that something is wrong when its happening. There's no crash or stack trace to look at. Unless you're monitoring your data integrity on a constant basis the only way you find out that you have an issue is when you end up charging a client $10,000 additional dollars or -$100 dollars or NaN dollars. There are ways to build eventually consistent systems. But that has to be a concious choice.

### Some partial solutions

There are a few partial solutions to this problem. The ones that I see most people reach for are either persistent connections, sticky sessions, or some combination of the two. Unfortunately none of these really eliminate the possibility of starting the same counter on two node, especially if more than one user can interact with a counter at a time. Additionally, introducing sticky sessions is a really quick way to end up with hot nodes due to unfair distribution of work. However, if you *can* use sticky sessions and are willing to give up on some levels of consistency than this might work for you.

Another partial solution is to always use [Compare and Swap](https://en.wikipedia.org/wiki/Compare-and-swap) (CAS) operations when updating the database. Assuming your database correctly implements a CAS than you eliminate the possibility of trampling data. But you will still return incorrect values until you do a write. Depending on your use case this might be an OK tradeoff.

Neither of these solutions fully solves the problem but they might be good enough for your usecase.

## Distributed Erlang will save us all.

Distribution is always the solutions thats begging for a problem. And there's no better problems then the ones introduced by a SGP. So lets indulge ourselves and walk down this path for a bit.

I'll assume that we've found a way to discover and connect our nodes together. Now that we've done that we need to register our counters across the cluster. For this example I'm going to use `:global` because its built in and easy to use. But the failures I'm about to describe are not limited to `:global`. You can induce these same failures with essentially any of the process registries that exist in elixir and erlang.

Converting our process to use the global registry is straight forward. We need to change the `start_link` function.

```elixir
defmodule CounterServer do
  def start_link(opts) do
    name = Keyword.get(opts, :name)
    GenServer.start_link(__MODULE__, opts, name: {:global, name})
  end
end
```

Now when we want to access our counter we'll be able to find it globally.

![connected nodes with a single counter]({{ site.url }}/assets/images/sgp/connected_nodes.jpg)

### The netsplit bogeyman

Netsplit is a catch all word that probably gets tossed around to much. I know I've been guilty of it. Colloquially its used as a fancy word to describe any and all faults that you could see in a distributed system. In practice the liklihood of seeing a netsplit will depend on the size of your cluster and the overall reliability of your network. You're much more likely to see faults in a 60 node cluster running in a k8s cluster on amazon's crappy network then if you're running 2 bare metal boxes in a co-lo somewhere. But if you run a system for long enough you'll eventually see faults. When you see those faults you need to have a plan for handling inconsistent state - even if that plan is "Fuck it who cares".

Unfortunately the SGP doesn't lend itself to graceful recovery after a netsplit. Lets talk through some of the issues.

If a netsplit occurs between your boxes it means that 1 of 2 major things has happend: a node has shutdown either expectedly or unexpectedly or the nodes have disconnected from each other but are all still running. The trick is that from the point of view of a single node you can't really deduce it was on your own.

![connected nodes with a single counter]({{ site.url }}/assets/images/sgp/partitioned_nodes.jpg)

If we take a naive approach with our counter process and start them when they aren't discoverable then during a partition we'll end up back in a situation where we have 2 counter processes running on separate nodes.

![partitioned nodes with counters]({{ site.url }}/assets/images/sgp/partitioned_nodes_with_counters.jpg)

When the partition heals we'll need to reconcile which counter is the canonical one. By default `:global` discards one at random.

### Node monitors will not save you

One of the ways that we can try to solve this is by using node monitors

```elixir
:net_kernel.monitor_nodes(true, [:nodedown_reason])
```

Calling this in a GenServer will cause node events to be sent to the process as messages. Unfortunately this isn't really enough to know the state of your cluster. From any nodes view its just not possible to know if another node has left for good, been autoscaled away, or been disconnected because it couldn't keep up with health checks.

So how can we solve this? Well here are the two examples.

### Consistent Hashing and Oracles

[Consistent hashing](https://en.wikipedia.org/wiki/Consistent_hashing) is a reasonable way to solve this problem. The basic scheme is that you'll use a consistent hashing algorithm to decide where a given counter process lives (Discord has a good library for this: [ex_hash_ring](https://github.com/discordapp/ex_hash_ring)). But in order to do this well we'll need a way to specify the canonical set of nodes. As we described above we can't reliably use node events.

One way of doing this is to issue specific RPCs that set the cluster configuration. If we do this then we need to ensure that we run this command to each node in the cluster instead of relying on internal distribution. If we were to rely on internal distribution to propogate we could easily end up in a situation where only a subset of our cluster was aware of the change.

![cluster change during partition]({{ site.url }}/assets/images/sgp/cluster_change_during_partition.jpg).

Another solution is to use an external, consistent store to cluster state. Most often this means using something like ETCD or Zookeeper which can provide high availability, consistent lookups.

In either scenario autoscaling as we typically think of it is off the table. You'll need to invest time into your deployment and cluster management to pull this off.

### CRDTs everywhere

Another way to solve the SGP inconsistency problem is to use CRDTs everywhere. You'll still get incorrect data during a netsplit and when persisting data to a durable store you'll need to merge the data in the store first and then use a CAS operation to put it back into the database. CRDTs have a lot of nice qualities to them but you need to ensure you are using them well. Consistency is not a composable quality. I also strongly advise you not to build your own (other than for fun) and instead look at something like LASP for use in production.

### Just don't use the SGP

Most of these problems go away if you simply don't use a single global process to hold your state. Its an easy pattern to reach for and it _feels_ elegant. But you really need to step back and ask yourself why you're doing this and if you're ready to solve all of the additional problems this solution will bring. If you only need a cache of values than maybe you're better off replicating all of your state to all of your nodes instead. If you're trying to serialize side-effects then maybe you're better off relying on idempotency and the consistency guarantees of your database. Maybe you can still keep these semantics but utilize something like [Maestro](https://github.com/toniqsystems/maestro) or [Datomic](https://www.datomic.com) to solve these consitency problems for you.

## When is this pattern OK?

There's always tradeoffs when building software and there are times when an SGP is a reasonable solution to the problem at hand. For me this is when the process is short lived and will mutate no external state. In fact just the other day I needed to build a search feature. In order for the feature to work we needed to gather data from lots of downstream sources and join it all together. Rather than do the data fetching every time a search was changed slightly, I did it once, put the state in a process, and then was able to quickly search through everything I had already found with very few additional calls required. This pattern worked quite well because I wasn't trying to execute mutations from inside the process.

I think this is also a fine pattern if you truly don't care about the consistency of the data you're manipulating. That sorta state isn't the norm in my experience. But it does exist and modeling it this way is probably fine.

## Conclusion

My goal with this post isn't to say that there's never any place for the SGP. My goal is to demonstrate that while easy to build and conceptually very elegant, the SGP is one of the more complicated patterns you can add to your system. I personally think its a pattern that is overused in elixir. Most importantly I want you to be aware of the kinds of problems that you'll face and the kinds of solutions that you'll need to work through. If you're prepared to do that and its a meaningful use of your companies time then its likely that it can work well for you. But you need to have clear eyes to see what you're facing.
